{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import time\n",
    "import os\n",
    "import nltk\n",
    "import gzip\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20802\n"
     ]
    }
   ],
   "source": [
    "caesar = nltk.corpus.gutenberg.raw('shakespeare-caesar.txt')\n",
    "caesar_prep = gensim.utils.simple_preprocess(caesar, min_len=1)\n",
    "print(len(caesar_prep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing model (this may take several minutes)...\n",
      "Traing model completed.\n"
     ]
    }
   ],
   "source": [
    "# print ('Loading data into model...')\n",
    "# model = gensim.models.KeyedVectors.load('model_gensim')\n",
    "print ('Traing model (this may take several minutes)...')\n",
    "model = gensim.models.Word2Vec([caesar_prep], size=1000, window=10, min_count=2, workers=10)\n",
    "model.train([caesar_prep],total_examples=len(caesar_prep),epochs=3)\n",
    "print ('Traing model completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model is saved.\n"
     ]
    }
   ],
   "source": [
    "print ('Saving model...')\n",
    "model.wv.save('model_gensim')\n",
    "print ('Model is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is ready to use.\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.KeyedVectors.load('model_gensim')\n",
    "print ('Model is ready to use.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar to \"more\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('a', 0.9999938011169434),\n",
       " ('caesar', 0.9999938011169434),\n",
       " ('to', 0.9999938011169434),\n",
       " ('i', 0.9999938011169434),\n",
       " ('that', 0.9999938011169434),\n",
       " ('of', 0.9999937415122986),\n",
       " ('and', 0.9999937415122986),\n",
       " ('then', 0.9999936819076538),\n",
       " ('your', 0.9999936819076538),\n",
       " ('be', 0.999993622303009)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'more'\n",
    "print ('similar to \"{}\"'.format (w1))\n",
    "model.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between two identical words\n",
      "1.0\n",
      "\n",
      "similarity between two different words\n",
      "0.99969995\n",
      "\n",
      "similarity between two opposit words\n",
      "0.99998295\n"
     ]
    }
   ],
   "source": [
    "# it's obvious bad result((((((\n",
    "print('similarity between two identical words')\n",
    "print (model.similarity(w1=\"bad\",w2=\"bad\"))\n",
    "\n",
    "print ('\\nsimilarity between two different words')\n",
    "print (model.similarity(w1=\"bad\",w2=\"mean\"))\n",
    "\n",
    "print ('\\nsimilarity between two opposit words')\n",
    "print(model.similarity(w1=\"bad\",w2=\"good\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Load pretrained vectors \n",
    "\n",
    "</font>\n",
    "\n",
    "- `words`: set of words in the vocabulary.\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "path = os.path.join(cwd, 'data')\n",
    "fn_glove= os.path.join(path , 'glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: 9.124s\n"
     ]
    }
   ],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "\n",
    "    return words, word_to_vec_map\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "words, word_to_vec_map = read_glove_vecs(fn_glove)\n",
    "time_loading = time.time()\n",
    "print('loading: {:.3f}s'.format(time_loading - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the function cosine_similarity() to evaluate similarity between word vectors.\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Reflects the degree of similariy between u and v\n",
    "    Arguments:\n",
    "        u, v - words vectors of shape (n,)          \n",
    "    Returns:\n",
    "        the cosine similarity between u and v defined by the formula above.\n",
    "    \"\"\"\n",
    "    \n",
    "    # START CODE \n",
    "    # Compute  cosine similarity between u and v \n",
    "    cosine_similarity = 1 - spatial.distance.cosine(u, v)\n",
    "    # END CODE\n",
    "    \n",
    "    return cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity(father, mother) =  0.8909038442893619\n",
      "cosine_similarity(ball, crocodile) =  0.27439246261379424\n",
      "cosine_similarity(france - paris, rome - italy) =  -0.67514793081742\n"
     ]
    }
   ],
   "source": [
    "father = word_to_vec_map[\"father\"]\n",
    "mother = word_to_vec_map[\"mother\"]\n",
    "ball = word_to_vec_map[\"ball\"]\n",
    "crocodile = word_to_vec_map[\"crocodile\"]\n",
    "france = word_to_vec_map[\"france\"]\n",
    "italy = word_to_vec_map[\"italy\"]\n",
    "paris = word_to_vec_map[\"paris\"]\n",
    "rome = word_to_vec_map[\"rome\"]\n",
    "\n",
    "print(\"cosine_similarity(father, mother) = \", cosine_similarity(father, mother))\n",
    "print(\"cosine_similarity(ball, crocodile) = \",cosine_similarity(ball, crocodile))\n",
    "print(\"cosine_similarity(france - paris, rome - italy) = \",cosine_similarity(france - paris, rome - italy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Analogy reasoning task\n",
    "\n",
    "</font>\n",
    "\n",
    "\n",
    "Analogy reasoning task is to complete the sentence `\"A\"` is to `\"B\"` as `\"C\"` is to `?`, e.g. `man` is to `woman` as `king` is to `queen`'\n",
    "\n",
    "In detail, it looks for word `\"D\"`, s.t. the embedding words vectors $E_a, E_b, E_c, E_d$ are related in the following: $E_b - E_a \\approx E_d - E_c$. \n",
    "\n",
    "Use cosine similarity to measure the similarity between $E_b - E_a$ and $E_d - E_c$ . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code of complete_analogy to perform word analogies\n",
    "\n",
    "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Finds answer for the analogy reasoning task: a is to b as c is to ? \n",
    "    \n",
    "    Arguments:\n",
    "    word_a, word_b, word_c  - string\n",
    "    word_to_vec_map - dictionary that maps words to embedding vectors. \n",
    "    \n",
    "    Returns:\n",
    "    best_word -  the word such that v_b - v_a is close to v_best_word - v_c, as measured by cosine similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert words to lower case\n",
    "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
    "    \n",
    "    # START CODE \n",
    "    # Get the word embeddings v_a, v_b and v_c \n",
    "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
    "        \n",
    "    words = word_to_vec_map.keys()\n",
    "    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n",
    "    best_word = None                   # Initialize best_word with None, it will help keep track of the word to output\n",
    "\n",
    "    # loop over the whole word vector set\n",
    "    for w in words:        \n",
    "        # to avoid best_word being one of the input words, pass on them.\n",
    "        if w in [word_a, word_b, word_c] :\n",
    "            continue        \n",
    "        \n",
    "        # Compute cosine similarity between the vector (e_b - e_a) and the vector ((w's vector representation) - e_c)\n",
    "        cosine_sim = 1 - spatial.distance.cosine((e_b - e_a), (word_to_vec_map[w] - e_c))\n",
    "       \n",
    "        # If the cosine_sim is more than the max_cosine_sim seen so far,\n",
    "            # then: set the new max_cosine_sim to the current cosine_sim and the best_word to the current word \n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best_word = w\n",
    "    # END CODE\n",
    "        \n",
    "    return best_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to test your code, this may take 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italy -> italian as spain -> spanish\n",
      "india -> delhi as japan -> tokyo\n",
      "man -> woman as boy -> girl\n",
      "small -> smaller as large -> larger\n"
     ]
    }
   ],
   "source": [
    "triads_to_try = [('italy', 'italian', 'spain'), ('india', 'delhi', 'japan'), ('man', 'woman', 'boy'), ('small', 'smaller', 'large')]\n",
    "for triad in triads_to_try:\n",
    "    print ('{} -> {} as {} -> {}'.format(*triad, complete_analogy(*triad,word_to_vec_map)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Compare with spacy \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302759333621871"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boy = word_to_vec_map[\"boy\"]\n",
    "girl = word_to_vec_map[\"girl\"]\n",
    "man = word_to_vec_map[\"man\"]\n",
    "woman = word_to_vec_map[\"woman\"]\n",
    "# analogy reasoning \n",
    "u = boy - man \n",
    "v = girl - woman\n",
    "cosine_similarity(u, v) #   0.73 better than 0.28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boy vs man: 0.8564431790318322 \n",
      "girl vs woman: 0.9065280671323898 \n"
     ]
    }
   ],
   "source": [
    "print  ('{} vs {}: {} '.format('boy', 'man', cosine_similarity(boy, man)))\n",
    "print  ('{} vs {}: {} '.format('girl', 'woman',  cosine_similarity(girl, woman)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car vs vehicle: 0.8833684148214743 \n"
     ]
    }
   ],
   "source": [
    "print  ('{} vs {}: {} '.format(\n",
    "    'car', 'vehicle', cosine_similarity(word_to_vec_map[\"car\"], word_to_vec_map[\"vehicle\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boy -> girl as man -> woman\n"
     ]
    }
   ],
   "source": [
    "triad = ('boy', 'girl', 'man')\n",
    "print ('{} -> {} as {} -> {}'.format(*triad, complete_analogy(*triad,word_to_vec_map)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
